Databases and data systems we use in our daily lives reflect many values and assumptions of the people who design them. In the article about a Pakistani man who failed to update his national ID because his mother didn’t register as married, we see this database has unintentionally created inequality by making assumptions about family members from their conservative cultural backgrounds. A lot of current database systems also reinforce existing social structures such as education, religion, economic position and gender. If some people use these databases to prioritize certain groups of customers according to their social structures, their actions will result in unfair treatment of the customers. For example, people from areas with higher crime rates may be charged more on insurance pricing. Some hospitals may prioritize appointments for patients with private insurance since they bring more revenue by paying a high annual healthcare insurance fee.
Moreover, databases can marginalize specific groups by failing to account for their needs. For example, platforms that are not designed to accommodate people with disabilities can create barriers. Also, low-income individuals or families may fail to build their credit scoring system, resulting in difficulty applying for mortgages.
Considering the relationship between technology and society, an important aspect that we are currently experiencing is the immersive interaction with social media. It has been known to many people that social media algorithms are able to recommend news and videos based on customers’ preferences, which comes from the user data they build up since their registration. This definitely can cause privacy and fairness concerns.
In summary, databases and data systems should be built with a sense of equality and fairness, and it is important for the designers to deliver inclusive systems that recognize and accommodate the diverse needs of all users.

