This article mainly talks about the hidden human work behind AI systems development as well as the ethical problems that come with it. Many people (including me, so this article gives me surprising facts) think AI only consists of pieces of code that are very high-tech and difficult to understand, but in reality, it depends a lot on human labor. The term ‘labor’ here means repeating work which is simple but time-consuming and often low-paid, such as the labelling work mentioned in the article. 
Because the massive amount of data that AI models deal with comes from human labor, the issue of bias is often raised to our attention. It should be challenging to test if those inputs to AI models by humans are correct and appropriate or not; therefore, unfair results can be generated if the training dataset has some problems. The proliferation of LLMs makes it more possible to spread misinformation or produce biased and harmful content since the models themselves are more like tools and cannot justify the reality of the information they accept and produce.
Speaking of the above, AI scientists need to focus more on content moderation. People need to consider the risks that AI bias brings to the users. Finding ways to control how these models are used and detecting their problems can be challenging but also necessary. As also mentioned in the writing component of assignment one, we are currently experiencing immersive interactions with social media, most of which have employed AI models to predict user preferences and generate content accordingly. It is essential to maintain a safer and fairer internet environment for the users where AI plays an important role. AI is a tool but not just a tool, as it is built and maintained by humans. To use AI responsibly, people need to address these ethical problems and create better policies for the future.
